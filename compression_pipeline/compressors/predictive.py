'''
predictive.py

This module contains helper functions for implementing the predictive coding
compressor.
'''

import numpy as np
from preprocessors.predictive import extract_training_pairs
from utilities import name_to_context_pixels, predictions_to_pixels, \
    get_valid_pixels_for_predictions

def predictive_comp(data, predictors, evaluation_context, true_pixels, n_prev,
    pcs, ccs, mode):
    '''
    Predictive Coding Compressor

    Args:
        data: numpy array
            data to be compressed
        predictors: list
            list of sklearn predictor models
        evaluation_context: numpy array
            array of contexts used to predict each pixel
        true_pixels: numpy array
            actual value of each pixel
        n_prev: int
            number of previous elements in the data set used by predictor
        pcs: string
            string representing the shape of contexts used for previous images
        ccs: string
            string representing the shape of contexts used for current images
        mode: string, 'single' or 'triple'
            string indicating whether 1 or 3 predictors are used

    Returns:
        compression: (numpy array, numpy array, list)
            tuple containing the error string generated by prediction, the
            residual pixels which are not predicted becaused they are needed
            for context, and the list of predictors used
        compression_metadata: None
            no new metadata is needed for decompression
        original_shape: tuple
            shape of original data
    '''

    assert evaluation_context is not None
    assert true_pixels is not None

    n_pred = len(predictors)
    dtype = data.dtype
    current_context_indices = name_to_context_pixels(ccs)
    prev_context_indices = name_to_context_pixels(pcs)

    pixel_preds = get_valid_pixels_for_predictions(data[0].shape, current_context_indices, prev_context_indices, False)
    num_pixels_to_predict = (pixel_preds[1] - pixel_preds[0] + 1) * (pixel_preds[3] - pixel_preds[2] + 1) \
                            * (data.shape[0] - n_prev)
    print("expecting num_pixels_to_predict = ", num_pixels_to_predict, "and got", true_pixels.shape[1])
    # If true, it means the predictor was trained on a subset of the original data (for size or
    # performance reasons), so we must grab the context for each pixel and its value on the fly.
    should_extract_context_on_fly = (true_pixels.shape[1] != num_pixels_to_predict)

    # Based on the dimensions of true_pixels and the value of mode, determine
    # how to shape the residuals for the most convenient computations
    in_cubist_mode = n_pred != true_pixels.shape[0]
    if true_pixels.ndim == 3:
        # RGB triples
        assert mode == 'single'
        to_reshape = (-1, true_pixels.shape[-1])
        residuals = np.empty((0, true_pixels.shape[-1]), dtype=dtype)
        error_string_dims = (1, num_pixels_to_predict, 3)
    elif true_pixels.ndim == 2:
        if mode == 'single':
            # Grayscale singles
            to_reshape = (-1,)
            residuals = np.empty((0,), dtype=dtype)
            error_string_dims = (1, num_pixels_to_predict)
        elif mode == 'triple':
            # RGB singles
            to_reshape = (-1, true_pixels.shape[0])
            residuals = np.empty((0, true_pixels.shape[0]), dtype=dtype)
            error_string_dims = (3, num_pixels_to_predict)
    else:
        print('Bad shape for true_pixels.')
        exit(-1)
    error_string = np.empty(error_string_dims, dtype=dtype)
    # Build error string by running each pixel through the predictor, batching
    # the data keep memory use reasonable
    remaining_samples_to_predict = num_pixels_to_predict
    start_index = 0
    imgs_processed = min(data.shape[0], 10)
    if should_extract_context_on_fly:
        context_string_reservoir, true_pixel_reservoir = extract_training_pairs(data[n_prev:n_prev+imgs_processed],
                                                                                n_prev,
                                                                                prev_context_indices,
                                                                                current_context_indices)
        context_string_reservoir = np.array(context_string_reservoir)
        context_string_reservoir = np.reshape(context_string_reservoir, (-1,) + evaluation_context.shape[1:])
        true_pixel_reservoir = np.array(true_pixel_reservoir)
    while remaining_samples_to_predict > 0:
        predict_batch_size = min(remaining_samples_to_predict, 1 if in_cubist_mode else 1000)
        s = start_index
        e = start_index + predict_batch_size
        if in_cubist_mode:
            assert mode == 'single', "Cubist + triple mode is unimplemented"
            # TODO actually batch for cubist
            num_predicates_applicable = 0
            predicted_pixel = 0.0
            for predicate, model in predictors:
                assert not should_extract_context_on_fly, "Cubist mode not compatible with |should_extract_context_on_the_fly|"
                # TODO get cubist mode working with |should_extract_context_on_the_fly|
                if eval(predicate, {'x' : evaluation_context[s]}):
                    predicted_pixel += model.predict([evaluation_context[s]])
                    num_predicates_applicable += 1
            predicted_pixel /= num_predicates_applicable
            estimated_pixel = predictions_to_pixels(predicted_pixel, dtype)
            error_string[0][s] = true_pixels[0][s] - estimated_pixel
        else:
            if should_extract_context_on_fly:
                print("size of context_string_reservoir", context_string_reservoir.shape)
                print("size of true_pixel_reservoir", true_pixel_reservoir.shape)
                print("s=",s,"e=",e)
                if len(true_pixel_reservoir) < predict_batch_size:
                    #20 20 1000 376 1000
                    print(data.shape[0], imgs_processed, predict_batch_size, len(true_pixel_reservoir), predict_batch_size)
                    addl_imgs_to_process = min(data.shape[0] - imgs_processed, 10)
                    if addl_imgs_to_process == 0:
                        predict_batch_size = len(true_pixel_reservoir)
                        break
                    assert addl_imgs_to_process > 0
                    addl_contexts, addl_true_pixels = extract_training_pairs(data[imgs_processed:imgs_processed+addl_imgs_to_process],
                                                                             n_prev,
                                                                             prev_context_indices,
                                                                             current_context_indices)
                    imgs_processed += addl_imgs_to_process
                    addl_contexts = np.array(addl_contexts)
                    addl_contexts = np.reshape(addl_contexts, (-1,) + evaluation_context.shape[1:])
                    context_string_reservoir = np.vstack((context_string_reservoir, addl_contexts))
                    true_pixel_reservoir = np.vstack((true_pixel_reservoir, np.array(addl_true_pixels)))
                    print("after adding stuff to reservoir, shape is", true_pixel_reservoir.shape)
                    print("size of context_string_reservoir", context_string_reservoir.shape)
        for i in range(n_pred):
            if should_extract_context_on_fly:
                contexts_for_eval = context_string_reservoir[0:predict_batch_size]
                true_pixels_for_eval = true_pixel_reservoir[i][0:predict_batch_size]
            else:
                print("taking s",s,"to e",e)
                contexts_for_eval = evaluation_context[s:e]
                true_pixels_for_eval = true_pixels[i][s:e]    
                
            predictions = predictors[i].predict(contexts_for_eval)
            estimated_pixels = predictions_to_pixels(predictions, dtype)
            error_string[i][s:e] = true_pixels_for_eval - estimated_pixels
        if should_extract_context_on_fly:
            context_string_reservoir = np.delete(context_string_reservoir, slice(0, predict_batch_size), axis=0)
            true_pixel_reservoir = np.delete(true_pixel_reservoir, slice(0, predict_batch_size), axis=0)
            print("post-deletion size of context_string_reservoir", context_string_reservoir.shape)
            print("size of true_pixel_reservoir", true_pixel_reservoir.shape)

        start_index += predict_batch_size
        remaining_samples_to_predict -= predict_batch_size

    # Build residuals by slicing every image in the data set based on the
    # context strings
    r_start, r_end, c_start, c_end = \
        get_valid_pixels_for_predictions(data[0].shape,
            current_context_indices, prev_context_indices)
    # +1 to use for half-open ranges
    r_end += 1
    c_end += 1
    residuals = np.append(residuals,
        data[:n_prev].reshape(to_reshape), axis=0)
    for img in data[n_prev:]:
        residuals = np.append(residuals,
            img[:r_start,:].reshape(to_reshape), axis=0)
        residuals = np.append(residuals,
            img[r_start:,:c_start].reshape(to_reshape), axis=0)
        residuals = np.append(residuals,
            img[r_end:,c_start:].reshape(to_reshape), axis=0)
        residuals = np.append(residuals,
            img[r_start:r_end,c_end:].reshape(to_reshape), axis=0)

    # Assert that every pixel is accounted for, either in residuals or in
    # error strings
    if true_pixels.ndim == 3:
        assert residuals.shape[0] + error_string.shape[1] == \
            np.prod(data.shape[:-1])
    elif true_pixels.ndim == 2:
        if mode == 'single':
            assert residuals.shape[0] + error_string.shape[1] == \
                np.prod(data.shape)
        elif mode == 'triple':
            assert residuals.shape[0] + error_string.shape[1] == \
                np.prod(data.shape[:-1])

    return (error_string, residuals, predictors), None, data.shape


def predictive_decomp(error_string, residuals, predictors, n_prev, pcs, ccs,
    original_shape, mode, is_cubist_mode):
    '''
    Predictive Coding Decompressor

    See docstring on the corresponding compressor for more information.

    Args:
        error_string: numpy array
            array of errors generated by prediction
        residuals: numpy array
            array of residual pixels not predicted
        predictors: list
            list of predictors
        n_prev: int
            number of previous elements in the data set used by predictor
        pcs: string
            string representing the shape of contexts used for previous images
        ccs: string
            string representing the shape of contexts used for current images
        mode: string, 'single' or 'triple'
            string indicating whether 1 or 3 predictors are used
        original_shape: tuple
            shape of original data

    Returns:
        decompression: numpy array
            decompressed data
    '''

    dtype = error_string.dtype
    data = np.empty(original_shape, dtype=dtype)
    current_context_indices = name_to_context_pixels(ccs)
    prev_context_indices = name_to_context_pixels(pcs)
    r_start, r_end, c_start, c_end = \
        get_valid_pixels_for_predictions(original_shape[1:],
            current_context_indices, prev_context_indices)
    r_end += 1
    c_end += 1

    # Based on the dimensions of true_pixels and the value of mode, determine
    # how to shape error_string for the most convenient computations
    if error_string.ndim == 3:
        # RGB triples
        to_reshape = (1, original_shape[0]-n_prev, r_end-r_start, \
            c_end-c_start, 3)
    elif error_string.ndim == 2:
        if mode == 'single':
            # Grayscale singles
            to_reshape = (1, original_shape[0]-n_prev, r_end-r_start, \
            c_end-c_start)
        elif mode == 'triple':
            # RGB singles
            to_reshape = (3, original_shape[0]-n_prev, r_end-r_start, \
            c_end-c_start)
    errors = error_string.reshape(to_reshape)

    # Load residuals for the initial images
    to_pop = n_prev * original_shape[1] * original_shape[2]
    data[:n_prev], residuals = residuals[:to_pop].reshape((n_prev,
        *data.shape[1:])), residuals[to_pop:]

    # Decompress the remaining images
    for n in range(n_prev, original_shape[0]):
        # Load the residuals based on context strings
        data, residuals = load_residuals(data, residuals, n, r_start, r_end,
            c_start, c_end)

        # Run the predictor over remaining pixels
        for r in range(r_start, r_end):
            for c in range(c_start, c_end):
                context = get_context(data, n_prev, pcs, ccs, n, r, c)
                if is_cubist_mode:
                    num_predicates_applicable = 0
                    prediction = 0.0
                    for predicate, model in predictors:
                        context = context.flatten()
                        if eval(predicate, {'x' : context}):
                            prediction += model.predict([context])
                            num_predicates_applicable += 1
                    prediction /= num_predicates_applicable
                    prediction = predictions_to_pixels(prediction, dtype)
                    assert mode == 'single', "Cubist + triple mode not implemented"
                    data[n,r,c] = prediction + errors[0, n-n_prev, r-r_start, c-c_start]
                else:
                    for i in range(len(predictors)):
                        prediction = predictors[i].predict(context)
                        prediction = predictions_to_pixels(prediction, dtype)
                        if mode == 'triple':
                            data[n,r,c,i] = prediction + errors[i, n-n_prev,
                                                                r-r_start, c-c_start]
                        elif mode == 'single':
                            data[n,r,c] = prediction + errors[i, n-n_prev,
                                                              r-r_start, c-c_start]

    assert len(residuals) == 0, \
        f'Not all residuals were consumed: {len(residuals)} pixels leftover.'

    return data


def load_residuals(data, residuals, n, r_start, r_end, c_start, c_end):
    '''
    Helper function to get load resiudals based on the context string.
    Works by progressively popping off pixels from residuals from the top
    side of the image, then the left, then the bottom, then the right.
    This order matches the way the residuals are constructed.

    Args:
        data: numpy array
            array to load residuals into
        residuals: numpy array
            array to pull residuals from
        n: int
            index of image in data to load residuals into
        r_start: int
            starting residual row
        r_end: int
            ending residual row
        c_start: int
            starting residual column
        c_end: int
            ending residual column

    Returns:
        data: numpy array
            array updated with residuals added
        residuals: numpy array
            array updated with residuals subtracted
    '''

    nr = r_start
    nc = data.shape[2]
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,:r_start,:], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    nr = data.shape[1] - r_start
    nc = c_start
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,r_start:,:c_start], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    nr = data.shape[1] - r_end
    nc = data.shape[2] - c_start
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,r_end:,c_start:], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    nr = r_end - r_start
    nc = data.shape[2] - c_end
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,r_start:r_end,c_end:], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    return data, residuals


def get_context(data, n_prev, pcs, ccs, n, r, c):
    '''
    Helper function to get context pixels based on context strings for the
    pixel at data[n,r,c]. Used in the decompressor.

    Args:
        data: numpy array
            array to load context from
        n_prev: int
            number of previous elements in the data set used by predictor
        pcs: string
            string representing the shape of contexts used for previous images
        ccs: string
            string representing the shape of contexts used for current images
        n: int
            index of image in data for which to load context
        r: int
            row index of pixel for which to load context
        c: int
            column index of pixel for which to load context

    Returns:
        context: numpy array
            context information for the pixel at data[n,r,c]
    '''

    # Determine shape of context based on dimension of data
    # Effectively depends on mode ('triple' or 'single')
    if data.ndim == 4:
        context = np.empty((1, len(ccs)+len(pcs)*n_prev, data.shape[-1]))
    else:
        context = np.empty((1, len(ccs)+len(pcs)*n_prev))

    if ccs == 'DAB':
        context[0, 0] = data[n,r,c-1].flatten()
        context[0, 1] = data[n,r-1,c-1].flatten()
        context[0, 2] = data[n,r-1,c].flatten()
    elif ccs == 'DABC':
        context[0, 0] = data[n,r,c-1].flatten()
        context[0, 1] = data[n,r-1,c-1].flatten()
        context[0, 2] = data[n,r-1,c].flatten()
        context[0, 3] = data[n,r-1,c+1].flatten()
    else:
        print(f'Current context string {ccs} unsupported by decompressor.')
        exit(-1)

    if pcs == 'DAB':
        for p in range(n_prev):
            context[0, len(ccs)+3*p] = data[n-(p+1),r,c-1].flatten()
            context[0, len(ccs)+3*p+1] = data[n-(p+1),r-1,c-1].flatten()
            context[0, len(ccs)+3*p+2] = data[n-(p+1),r-1,c].flatten()
    elif pcs == 'DABC':
        for p in range(n_prev):
            context[0, len(ccs)+4*p] = data[n-(p+1),r,c-1].flatten()
            context[0, len(ccs)+4*p+1] = data[n-(p+1),r-1,c-1].flatten()
            context[0, len(ccs)+4*p+2] = data[n-(p+1),r-1,c].flatten()
            context[0, len(ccs)+4*p+3] = data[n-(p+1),r-1,c+1].flatten()
    elif pcs == 'DABX':
        for p in range(n_prev):
            context[0, len(ccs)+4*p] = data[n-(p+1),r,c-1].flatten()
            context[0, len(ccs)+4*p+1] = data[n-(p+1),r-1,c-1].flatten()
            context[0, len(ccs)+4*p+2] = data[n-(p+1),r-1,c].flatten()
            context[0, len(ccs)+4*p+3] = data[n-(p+1),r,c].flatten()
    else:
        print(f'Previous context string {pcs} unsupported by decompressor.')
        exit(-1)

    return context.reshape((1, -1))
