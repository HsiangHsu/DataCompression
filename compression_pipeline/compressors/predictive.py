'''
predictive.py

This module contains helper functions for implementing the predictive coding
compressor.
'''

import numpy as np
from utilities import name_to_context_pixels, predictions_to_pixels, \
    get_valid_pixels_for_predictions

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential

def predictive_comp(data, predictors, training_context, true_pixels, n_prev,
    pcs, ccs, mode):
    '''
    Predictive Coding Compressor

    Args:
        data: numpy array
            data to be compressed
        predictors: list
            list of sklearn predictor models
        training_context: numpy array
            array of contexts used to predict each pixel
        true_pixels: numpy array
            actual value of each pixel
        n_prev: int
            number of previous elements in the data set used by predictor
        pcs: string
            string representing the shape of contexts used for previous images
        ccs: string
            string representing the shape of contexts used for current images
        mode: string, 'single' or 'triple'
            string indicating whether 1 or 3 predictors are used

    Returns:
        compression: (numpy array, numpy array, list)
            tuple containing the error string generated by prediction, the
            residual pixels which are not predicted becaused they are needed
            for context, and the list of predictors used
        compression_metadata: None
            no new metadata is needed for decompression
        original_shape: tuple
            shape of original data
    '''

    assert training_context is not None
    assert true_pixels is not None

    n_pred = len(predictors)
    dtype = data.dtype
    current_context_indices = name_to_context_pixels(ccs)
    prev_context_indices = name_to_context_pixels(pcs)
    
    # Based on the dimensions of true_pixels and the value of mode, determine
    # how to shape the residuals for the most convenient computations
    in_cubist_mode = n_pred != true_pixels.shape[0]
    if true_pixels.ndim == 3:
        # RGB triples
        assert mode == 'single'
        to_reshape = (-1, true_pixels.shape[-1])
        residuals = np.empty((0, true_pixels.shape[-1]), dtype=dtype)
    elif true_pixels.ndim == 2:
        if mode == 'single':
            # Grayscale singles
            to_reshape = (-1,)
            residuals = np.empty((0,), dtype=dtype)
        elif mode == 'triple':
            # RGB singles
            to_reshape = (-1, true_pixels.shape[0])
            residuals = np.empty((0, true_pixels.shape[0]), dtype=dtype)
    else:
        print('Bad shape for true_pixels.')
        exit(-1)
    error_string = np.empty(true_pixels.shape, dtype=dtype)

    # Build error string by running each pixel through the predictor, batching
    # the data keep memory use reasonable
    if isinstance(predictors[0], keras.Sequential):
        # Quantile mode
        assert n_pred == 1
        predictions = np.argmax(predictors[0].predict(training_context, batch_size=50000), axis=1)
        
        # TODO this is messy to duplicate the logic from preprocessor...sigh
        q = np.quantile(true_pixels[0], np.linspace(0,1,31), interpolation='nearest')
        Yq = np.argmin(np.abs((true_pixels[0].reshape(-1,1).astype(np.int16) - \
                               q.reshape(1,-1).astype(np.int16))), axis=1)
        quantiles, _ = np.unique(Yq, return_counts=True) 
        
        # map predicted value to quantile
        predictions = np.array([q[quantiles[ix]] for ix in predictions])
        estimated_pixels = predictions_to_pixels(predictions, dtype)
        print("num pixels diff between |predictions| vs |estimated_pixels|", np.count_nonzero(predictions - estimated_pixels))
        error_string[0] = true_pixels[0] - estimated_pixels
    else:
        # Not quantile mode
        remaining_samples_to_predict = true_pixels.shape[1]
        start_index = 0
        while remaining_samples_to_predict > 0:
            predict_batch_size = min(remaining_samples_to_predict, 1 if in_cubist_mode else 1000)
            s = start_index
            e = start_index + predict_batch_size
            if in_cubist_mode:
                assert mode == 'single', "Cubist + triple mode is unimplemented"
                # TODO actually batch
            num_predicates_applicable = 0
            predicted_pixel = 0.0
            for predicate, model in predictors:
                if eval(predicate, {'x' : training_context[s]}):
                    predicted_pixel += model.predict([training_context[s]])
                    num_predicates_applicable += 1
                    predicted_pixel /= num_predicates_applicable
                    estimated_pixel = predictions_to_pixels(predicted_pixel, dtype)
                    error_string[0][s] = true_pixels[0][s] - estimated_pixel
                else:
                    for i in range(n_pred):
                        predictions = predictors[i].predict(training_context[s:e])
                        estimated_pixels = predictions_to_pixels(predictions, dtype)
                        error_string[i][s:e] = true_pixels[i][s:e] - estimated_pixels
                        start_index += predict_batch_size
                        remaining_samples_to_predict -= predict_batch_size

    # Build residuals by slicing every image in the data set based on the
    # context strings
    r_start, r_end, c_start, c_end = \
        get_valid_pixels_for_predictions(data[0].shape,
            current_context_indices, prev_context_indices)
    # +1 to use for half-open ranges
    r_end += 1
    c_end += 1
    residuals = np.append(residuals,
        data[:n_prev].reshape(to_reshape), axis=0)
    for img in data[n_prev:]:
        residuals = np.append(residuals,
            img[:r_start,:].reshape(to_reshape), axis=0)
        residuals = np.append(residuals,
            img[r_start:,:c_start].reshape(to_reshape), axis=0)
        residuals = np.append(residuals,
            img[r_end:,c_start:].reshape(to_reshape), axis=0)
        residuals = np.append(residuals,
            img[r_start:r_end,c_end:].reshape(to_reshape), axis=0)

    # Assert that every pixel is accounted for, either in residuals or in
    # error strings
    if true_pixels.ndim == 3:
        assert residuals.shape[0] + error_string.shape[1] == \
            np.prod(data.shape[:-1])
    elif true_pixels.ndim == 2:
        if mode == 'single':
            assert residuals.shape[0] + error_string.shape[1] == \
                np.prod(data.shape)
        elif mode == 'triple':
            assert residuals.shape[0] + error_string.shape[1] == \
                np.prod(data.shape[:-1])

    return (error_string, residuals, predictors), None, data.shape


def predictive_decomp(error_string, residuals, predictors, n_prev, pcs, ccs,
    original_shape, mode, is_cubist_mode):
    '''
    Predictive Coding Decompressor

    See docstring on the corresponding compressor for more information.

    Args:
        error_string: numpy array
            array of errors generated by prediction
        residuals: numpy array
            array of residual pixels not predicted
        predictors: list
            list of predictors
        n_prev: int
            number of previous elements in the data set used by predictor
        pcs: string
            string representing the shape of contexts used for previous images
        ccs: string
            string representing the shape of contexts used for current images
        mode: string, 'single' or 'triple'
            string indicating whether 1 or 3 predictors are used
        original_shape: tuple
            shape of original data

    Returns:
        decompression: numpy array
            decompressed data
    '''

    dtype = error_string.dtype
    data = np.empty(original_shape, dtype=dtype)
    current_context_indices = name_to_context_pixels(ccs)
    prev_context_indices = name_to_context_pixels(pcs)
    r_start, r_end, c_start, c_end = \
        get_valid_pixels_for_predictions(original_shape[1:],
            current_context_indices, prev_context_indices)
    r_end += 1
    c_end += 1

    # Based on the dimensions of true_pixels and the value of mode, determine
    # how to shape error_string for the most convenient computations
    if error_string.ndim == 3:
        # RGB triples
        to_reshape = (1, original_shape[0]-n_prev, r_end-r_start, \
            c_end-c_start, 3)
    elif error_string.ndim == 2:
        if mode == 'single':
            # Grayscale singles
            to_reshape = (1, original_shape[0]-n_prev, r_end-r_start, \
            c_end-c_start)
        elif mode == 'triple':
            # RGB singles
            to_reshape = (3, original_shape[0]-n_prev, r_end-r_start, \
            c_end-c_start)
    errors = error_string.reshape(to_reshape)

    # Load residuals for the initial images
    to_pop = n_prev * original_shape[1] * original_shape[2]
    data[:n_prev], residuals = residuals[:to_pop].reshape((n_prev,
        *data.shape[1:])), residuals[to_pop:]

    # Decompress the remaining images
    for n in range(n_prev, original_shape[0]):
        # Load the residuals based on context strings
        data, residuals = load_residuals(data, residuals, n, r_start, r_end,
            c_start, c_end)

        # Run the predictor over remaining pixels
        for r in range(r_start, r_end):
            for c in range(c_start, c_end):
                context = get_context(data, n_prev, pcs, ccs, n, r, c)
                if is_cubist_mode:
                    num_predicates_applicable = 0
                    prediction = 0.0
                    for predicate, model in predictors:
                        context = context.flatten()
                        if eval(predicate, {'x' : context}):
                            prediction += model.predict([context])
                            num_predicates_applicable += 1
                    prediction /= num_predicates_applicable
                    prediction = predictions_to_pixels(prediction, dtype)
                    assert mode == 'single', "Cubist + triple mode not implemented"
                    data[n,r,c] = prediction + errors[0, n-n_prev, r-r_start, c-c_start]
                else:
                    for i in range(len(predictors)):
                        prediction = predictors[i].predict(context)
                        prediction = predictions_to_pixels(prediction, dtype)
                        if mode == 'triple':
                            data[n,r,c,i] = prediction + errors[i, n-n_prev,
                                                                r-r_start, c-c_start]
                        elif mode == 'single':
                            data[n,r,c] = prediction + errors[i, n-n_prev,
                                                              r-r_start, c-c_start]

    assert len(residuals) == 0, \
        f'Not all residuals were consumed: {len(residuals)} pixels leftover.'

    return data


def load_residuals(data, residuals, n, r_start, r_end, c_start, c_end):
    '''
    Helper function to get load resiudals based on the context string.
    Works by progressively popping off pixels from residuals from the top
    side of the image, then the left, then the bottom, then the right.
    This order matches the way the residuals are constructed.

    Args:
        data: numpy array
            array to load residuals into
        residuals: numpy array
            array to pull residuals from
        n: int
            index of image in data to load residuals into
        r_start: int
            starting residual row
        r_end: int
            ending residual row
        c_start: int
            starting residual column
        c_end: int
            ending residual column

    Returns:
        data: numpy array
            array updated with residuals added
        residuals: numpy array
            array updated with residuals subtracted
    '''

    nr = r_start
    nc = data.shape[2]
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,:r_start,:], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    nr = data.shape[1] - r_start
    nc = c_start
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,r_start:,:c_start], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    nr = data.shape[1] - r_end
    nc = data.shape[2] - c_start
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,r_end:,c_start:], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    nr = r_end - r_start
    nc = data.shape[2] - c_end
    to_pop = nr*nc
    if data.ndim == 4:
        to_reshape = (nr, nc, data.shape[-1])
    else:
        to_reshape = (nr, nc)
    data[n,r_start:r_end,c_end:], residuals = \
        residuals[:to_pop].reshape(to_reshape), residuals[to_pop:]

    return data, residuals


def get_context(data, n_prev, pcs, ccs, n, r, c):
    '''
    Helper function to get context pixels based on context strings for the
    pixel at data[n,r,c]. Used in the decompressor.

    Args:
        data: numpy array
            array to load context from
        n_prev: int
            number of previous elements in the data set used by predictor
        pcs: string
            string representing the shape of contexts used for previous images
        ccs: string
            string representing the shape of contexts used for current images
        n: int
            index of image in data for which to load context
        r: int
            row index of pixel for which to load context
        c: int
            column index of pixel for which to load context

    Returns:
        context: numpy array
            context information for the pixel at data[n,r,c]
    '''

    # Determine shape of context based on dimension of data
    # Effectively depends on mode ('triple' or 'single')
    if data.ndim == 4:
        context = np.empty((1, len(ccs)+len(pcs)*n_prev, data.shape[-1]))
    else:
        context = np.empty((1, len(ccs)+len(pcs)*n_prev))

    if ccs == 'DAB':
        context[0, 0] = data[n,r,c-1].flatten()
        context[0, 1] = data[n,r-1,c-1].flatten()
        context[0, 2] = data[n,r-1,c].flatten()
    elif ccs == 'DABC':
        context[0, 0] = data[n,r,c-1].flatten()
        context[0, 1] = data[n,r-1,c-1].flatten()
        context[0, 2] = data[n,r-1,c].flatten()
        context[0, 3] = data[n,r-1,c+1].flatten()
    else:
        print(f'Current context string {ccs} unsupported by decompressor.')
        exit(-1)

    if pcs == 'DAB':
        for p in range(n_prev):
            context[0, len(ccs)+3*p] = data[n-(p+1),r,c-1].flatten()
            context[0, len(ccs)+3*p+1] = data[n-(p+1),r-1,c-1].flatten()
            context[0, len(ccs)+3*p+2] = data[n-(p+1),r-1,c].flatten()
    elif pcs == 'DABC':
        for p in range(n_prev):
            context[0, len(ccs)+4*p] = data[n-(p+1),r,c-1].flatten()
            context[0, len(ccs)+4*p+1] = data[n-(p+1),r-1,c-1].flatten()
            context[0, len(ccs)+4*p+2] = data[n-(p+1),r-1,c].flatten()
            context[0, len(ccs)+4*p+3] = data[n-(p+1),r-1,c+1].flatten()
    elif pcs == 'DABX':
        for p in range(n_prev):
            context[0, len(ccs)+4*p] = data[n-(p+1),r,c-1].flatten()
            context[0, len(ccs)+4*p+1] = data[n-(p+1),r-1,c-1].flatten()
            context[0, len(ccs)+4*p+2] = data[n-(p+1),r-1,c].flatten()
            context[0, len(ccs)+4*p+3] = data[n-(p+1),r,c].flatten()
    else:
        print(f'Previous context string {pcs} unsupported by decompressor.')
        exit(-1)

    return context.reshape((1, -1))
